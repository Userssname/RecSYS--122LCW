{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we want to forcast the ratings of the first 3000 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_csv('user_history.csv')\n",
    "step2 = pd.read_csv('3000_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we want to find the relationship between the website browsing time and ratings for the first 3000 users\n",
    "### then we use this relationship to predict the ratings of the other 1500 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_3000history = np.array(history.iloc[:3000,1:])\n",
    "y_3000rating = np.array(step2.iloc[:3000,2:])\n",
    "x_1500history = np.array(history.iloc[3000:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n",
      "(1500,)\n"
     ]
    }
   ],
   "source": [
    "# we first normalize the data\n",
    "def load_auto_data(x):\n",
    "    x_std = x.std(axis = 1)\n",
    "    print(x_std.shape)\n",
    "    x_mean = x.mean(axis = 1)\n",
    "    for i in range(len(x)):\n",
    "        x[i,:] = (x[i,:] - x_mean[i])/x_std[i]\n",
    "    return x\n",
    "x_3000history_norm = load_auto_data(x_3000history)   \n",
    "x_1500history_norm = load_auto_data(x_1500history)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take 90% of the first 3000 users as trainning set\n",
    "#Take 10% of the first 3000 users as testing set\n",
    "x_3000history_train = np.array(history.iloc[:2700,1:])\n",
    "x_3000history_test = np.array(history.iloc[2700:3000,1:])\n",
    "y_3000rating_train = np.array(step2.iloc[:2700,2:])\n",
    "y_3000rating_test = np.array(step2.iloc[2700:3000,2:])\n",
    "\n",
    "\n",
    "##segment method of training and testing ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2700 samples, validate on 300 samples\n",
      "Epoch 1/100\n",
      "2700/2700 [==============================] - 1s 466us/step - loss: 13.6872 - val_loss: 6.9910\n",
      "Epoch 2/100\n",
      "2700/2700 [==============================] - 1s 328us/step - loss: 6.8145 - val_loss: 6.3369\n",
      "Epoch 3/100\n",
      "2700/2700 [==============================] - 1s 310us/step - loss: 6.0469 - val_loss: 5.8587\n",
      "Epoch 4/100\n",
      "2700/2700 [==============================] - 1s 311us/step - loss: 5.7871 - val_loss: 5.6466\n",
      "Epoch 5/100\n",
      "2700/2700 [==============================] - 1s 310us/step - loss: 5.5061 - val_loss: 5.2860\n",
      "Epoch 6/100\n",
      "2700/2700 [==============================] - 1s 310us/step - loss: 5.2484 - val_loss: 5.1268\n",
      "Epoch 7/100\n",
      "2700/2700 [==============================] - 1s 310us/step - loss: 5.1507 - val_loss: 5.1041\n",
      "Epoch 8/100\n",
      "2700/2700 [==============================] - 1s 318us/step - loss: 5.1289 - val_loss: 5.1056\n",
      "Epoch 9/100\n",
      "2700/2700 [==============================] - 1s 316us/step - loss: 5.1182 - val_loss: 5.0582\n",
      "Epoch 10/100\n",
      "2700/2700 [==============================] - 1s 330us/step - loss: 5.1115 - val_loss: 5.1000\n",
      "Epoch 11/100\n",
      "2700/2700 [==============================] - 1s 326us/step - loss: 5.1130 - val_loss: 5.1073\n",
      "Epoch 12/100\n",
      "2700/2700 [==============================] - 1s 519us/step - loss: 5.0913 - val_loss: 5.0684\n",
      "Epoch 13/100\n",
      "2700/2700 [==============================] - 1s 347us/step - loss: 5.0921 - val_loss: 5.0485\n",
      "Epoch 14/100\n",
      "2700/2700 [==============================] - 1s 319us/step - loss: 5.0972 - val_loss: 5.0591\n",
      "Epoch 15/100\n",
      "2700/2700 [==============================] - 1s 374us/step - loss: 5.0866 - val_loss: 5.0544\n",
      "Epoch 16/100\n",
      "2700/2700 [==============================] - 1s 513us/step - loss: 5.0839 - val_loss: 5.0767\n",
      "Epoch 17/100\n",
      "2700/2700 [==============================] - 1s 381us/step - loss: 5.0840 - val_loss: 5.0633\n",
      "Epoch 18/100\n",
      "2700/2700 [==============================] - 1s 346us/step - loss: 5.0852 - val_loss: 5.0646\n",
      "Epoch 19/100\n",
      "2700/2700 [==============================] - 1s 320us/step - loss: 5.0791 - val_loss: 5.0623\n",
      "Epoch 20/100\n",
      "2700/2700 [==============================] - 1s 380us/step - loss: 5.0774 - val_loss: 5.0556\n",
      "Epoch 21/100\n",
      "2700/2700 [==============================] - 1s 351us/step - loss: 5.0751 - val_loss: 5.0630\n",
      "Epoch 22/100\n",
      "2700/2700 [==============================] - 1s 323us/step - loss: 5.0690 - val_loss: 5.0538\n",
      "Epoch 23/100\n",
      "2700/2700 [==============================] - 1s 329us/step - loss: 5.0635 - val_loss: 5.0731\n",
      "Epoch 24/100\n",
      "2700/2700 [==============================] - 1s 309us/step - loss: 5.0659 - val_loss: 5.0366\n",
      "Epoch 25/100\n",
      "2700/2700 [==============================] - 1s 357us/step - loss: 5.0630 - val_loss: 5.0204\n",
      "Epoch 26/100\n",
      "2700/2700 [==============================] - 1s 313us/step - loss: 5.0641 - val_loss: 5.0912\n",
      "Epoch 27/100\n",
      "2700/2700 [==============================] - 1s 316us/step - loss: 5.0673 - val_loss: 5.1033\n",
      "Epoch 28/100\n",
      "2700/2700 [==============================] - 1s 319us/step - loss: 5.0650 - val_loss: 5.0874\n",
      "Epoch 29/100\n",
      "2700/2700 [==============================] - 1s 322us/step - loss: 5.0606 - val_loss: 5.0159\n",
      "Epoch 30/100\n",
      "2700/2700 [==============================] - 1s 363us/step - loss: 5.0667 - val_loss: 5.0508\n",
      "Epoch 31/100\n",
      "2700/2700 [==============================] - 2s 561us/step - loss: 5.0621 - val_loss: 5.0536\n",
      "Epoch 32/100\n",
      "2700/2700 [==============================] - 1s 451us/step - loss: 5.0634 - val_loss: 5.0753\n",
      "Epoch 33/100\n",
      "2700/2700 [==============================] - 1s 364us/step - loss: 5.0658 - val_loss: 5.0240\n",
      "Epoch 34/100\n",
      "2700/2700 [==============================] - 1s 340us/step - loss: 5.0542 - val_loss: 5.1172\n",
      "Epoch 35/100\n",
      "2700/2700 [==============================] - 1s 325us/step - loss: 5.0619 - val_loss: 5.0463\n",
      "Epoch 36/100\n",
      "2700/2700 [==============================] - 1s 384us/step - loss: 5.0528 - val_loss: 5.0389\n",
      "Epoch 37/100\n",
      "2700/2700 [==============================] - 2s 556us/step - loss: 5.0525 - val_loss: 5.0463\n",
      "Epoch 38/100\n",
      "2700/2700 [==============================] - 1s 388us/step - loss: 5.0548 - val_loss: 5.0813\n",
      "Epoch 39/100\n",
      "2700/2700 [==============================] - 1s 336us/step - loss: 5.0509 - val_loss: 5.0404\n",
      "Epoch 40/100\n",
      "2700/2700 [==============================] - 1s 313us/step - loss: 5.0562 - val_loss: 5.0813\n",
      "Epoch 41/100\n",
      "2700/2700 [==============================] - 1s 316us/step - loss: 5.0524 - val_loss: 5.0368\n",
      "Epoch 42/100\n",
      "2700/2700 [==============================] - 1s 318us/step - loss: 5.0442 - val_loss: 5.0485\n",
      "Epoch 43/100\n",
      "2700/2700 [==============================] - 1s 337us/step - loss: 5.0493 - val_loss: 5.0373\n",
      "Epoch 44/100\n",
      "2700/2700 [==============================] - 1s 307us/step - loss: 5.0455 - val_loss: 5.0650\n",
      "Epoch 45/100\n",
      "2700/2700 [==============================] - 1s 309us/step - loss: 5.0430 - val_loss: 5.0213\n",
      "Epoch 46/100\n",
      "2700/2700 [==============================] - 1s 309us/step - loss: 5.0453 - val_loss: 5.0118\n",
      "Epoch 47/100\n",
      "2700/2700 [==============================] - 1s 307us/step - loss: 5.0406 - val_loss: 5.0203\n",
      "Epoch 48/100\n",
      "2700/2700 [==============================] - 1s 409us/step - loss: 5.0402 - val_loss: 5.0674\n",
      "Epoch 49/100\n",
      "2700/2700 [==============================] - 1s 318us/step - loss: 5.0366 - val_loss: 5.0467\n",
      "Epoch 50/100\n",
      "2700/2700 [==============================] - 1s 305us/step - loss: 5.0270 - val_loss: 5.0421\n",
      "Epoch 51/100\n",
      "2700/2700 [==============================] - 1s 300us/step - loss: 5.0281 - val_loss: 5.0330\n",
      "Epoch 52/100\n",
      "2700/2700 [==============================] - 1s 298us/step - loss: 5.0173 - val_loss: 5.0706\n",
      "Epoch 53/100\n",
      "2700/2700 [==============================] - 1s 320us/step - loss: 5.0203 - val_loss: 5.0132\n",
      "Epoch 54/100\n",
      "2700/2700 [==============================] - 1s 297us/step - loss: 5.0284 - val_loss: 5.0397\n",
      "Epoch 55/100\n",
      "2700/2700 [==============================] - 1s 434us/step - loss: 5.0170 - val_loss: 5.0641\n",
      "Epoch 56/100\n",
      "2700/2700 [==============================] - 2s 677us/step - loss: 5.0221 - val_loss: 5.0719\n",
      "Epoch 57/100\n",
      "2700/2700 [==============================] - 2s 919us/step - loss: 5.0164 - val_loss: 5.0267\n",
      "Epoch 58/100\n",
      "2700/2700 [==============================] - 2s 666us/step - loss: 5.0116 - val_loss: 5.0162\n",
      "Epoch 59/100\n",
      "2700/2700 [==============================] - 1s 324us/step - loss: 5.0076 - val_loss: 5.0204\n",
      "Epoch 60/100\n",
      "2700/2700 [==============================] - 1s 309us/step - loss: 5.0040 - val_loss: 5.0251\n",
      "Epoch 61/100\n",
      "2700/2700 [==============================] - 1s 303us/step - loss: 5.0059 - val_loss: 5.0255\n",
      "Epoch 62/100\n",
      "2700/2700 [==============================] - 1s 365us/step - loss: 5.0005 - val_loss: 5.0480\n",
      "Epoch 63/100\n",
      "2700/2700 [==============================] - 1s 295us/step - loss: 4.9989 - val_loss: 5.0357\n",
      "Epoch 64/100\n",
      "2700/2700 [==============================] - 1s 299us/step - loss: 4.9902 - val_loss: 5.0829\n",
      "Epoch 65/100\n",
      "2700/2700 [==============================] - 1s 293us/step - loss: 4.9851 - val_loss: 5.0726\n",
      "Epoch 66/100\n",
      "2700/2700 [==============================] - 1s 287us/step - loss: 4.9874 - val_loss: 5.0236\n",
      "Epoch 67/100\n",
      "2700/2700 [==============================] - 1s 286us/step - loss: 4.9799 - val_loss: 5.0838\n",
      "Epoch 68/100\n",
      "2700/2700 [==============================] - 1s 370us/step - loss: 4.9809 - val_loss: 5.0712\n",
      "Epoch 69/100\n",
      "2700/2700 [==============================] - 1s 424us/step - loss: 4.9772 - val_loss: 5.0558\n",
      "Epoch 70/100\n",
      "2700/2700 [==============================] - 2s 868us/step - loss: 4.9677 - val_loss: 5.0904\n",
      "Epoch 71/100\n",
      "2700/2700 [==============================] - 1s 344us/step - loss: 4.9632 - val_loss: 5.1123\n",
      "Epoch 72/100\n",
      "2700/2700 [==============================] - 1s 529us/step - loss: 4.9769 - val_loss: 5.0379\n",
      "Epoch 73/100\n",
      "2700/2700 [==============================] - 1s 322us/step - loss: 4.9526 - val_loss: 5.1347\n",
      "Epoch 74/100\n",
      "2700/2700 [==============================] - 2s 602us/step - loss: 4.9597 - val_loss: 5.1036\n",
      "Epoch 75/100\n",
      "2700/2700 [==============================] - 1s 502us/step - loss: 4.9524 - val_loss: 5.1425\n",
      "Epoch 76/100\n",
      "2700/2700 [==============================] - 1s 333us/step - loss: 4.9423 - val_loss: 5.1261\n",
      "Epoch 77/100\n",
      "2700/2700 [==============================] - 1s 347us/step - loss: 4.9344 - val_loss: 5.0994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "2700/2700 [==============================] - 1s 311us/step - loss: 4.9262 - val_loss: 5.1112\n",
      "Epoch 79/100\n",
      "2700/2700 [==============================] - 1s 296us/step - loss: 4.9238 - val_loss: 5.1188\n",
      "Epoch 80/100\n",
      "2700/2700 [==============================] - 1s 298us/step - loss: 4.9360 - val_loss: 5.1360\n",
      "Epoch 81/100\n",
      "2700/2700 [==============================] - 1s 306us/step - loss: 4.9278 - val_loss: 5.1636\n",
      "Epoch 82/100\n",
      "2700/2700 [==============================] - 1s 549us/step - loss: 4.9126 - val_loss: 5.1490\n",
      "Epoch 83/100\n",
      "2700/2700 [==============================] - 1s 392us/step - loss: 4.8972 - val_loss: 5.1308\n",
      "Epoch 84/100\n",
      "2700/2700 [==============================] - 1s 322us/step - loss: 4.8885 - val_loss: 5.2419\n",
      "Epoch 85/100\n",
      "2700/2700 [==============================] - 1s 474us/step - loss: 4.8889 - val_loss: 5.2130\n",
      "Epoch 86/100\n",
      "2700/2700 [==============================] - 1s 354us/step - loss: 4.8931 - val_loss: 5.1359\n",
      "Epoch 87/100\n",
      "2700/2700 [==============================] - 1s 333us/step - loss: 4.8866 - val_loss: 5.1794\n",
      "Epoch 88/100\n",
      "2700/2700 [==============================] - 1s 450us/step - loss: 4.8604 - val_loss: 5.2297\n",
      "Epoch 89/100\n",
      "2700/2700 [==============================] - 2s 662us/step - loss: 4.8663 - val_loss: 5.2189\n",
      "Epoch 90/100\n",
      "2700/2700 [==============================] - 1s 463us/step - loss: 4.8636 - val_loss: 5.2350\n",
      "Epoch 91/100\n",
      "2700/2700 [==============================] - 1s 332us/step - loss: 4.8606 - val_loss: 5.1811\n",
      "Epoch 92/100\n",
      "2700/2700 [==============================] - 1s 482us/step - loss: 4.8508 - val_loss: 5.2425\n",
      "Epoch 93/100\n",
      "2700/2700 [==============================] - 1s 336us/step - loss: 4.8319 - val_loss: 5.2547\n",
      "Epoch 94/100\n",
      "2700/2700 [==============================] - 1s 320us/step - loss: 4.8295 - val_loss: 5.2572\n",
      "Epoch 95/100\n",
      "2700/2700 [==============================] - 1s 324us/step - loss: 4.8428 - val_loss: 5.1964\n",
      "Epoch 96/100\n",
      "2700/2700 [==============================] - 1s 305us/step - loss: 4.8192 - val_loss: 5.2014\n",
      "Epoch 97/100\n",
      "2700/2700 [==============================] - 1s 302us/step - loss: 4.8212 - val_loss: 5.2537\n",
      "Epoch 98/100\n",
      "2700/2700 [==============================] - 1s 315us/step - loss: 4.8387 - val_loss: 5.2303\n",
      "Epoch 99/100\n",
      "2700/2700 [==============================] - 1s 301us/step - loss: 4.8080 - val_loss: 5.3168\n",
      "Epoch 100/100\n",
      "2700/2700 [==============================] - 1s 294us/step - loss: 4.8475 - val_loss: 5.2582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b8f99bc348>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we build a neutron network model\n",
    "import keras\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50,activation='relu'))\n",
    "model.add(keras.layers.Dense(10,activation='relu'))\n",
    "model.add(keras.layers.Dense(100,activation=None))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(x_3000history_train, y_3000rating_train, validation_data=(x_3000history_test, y_3000rating_test), epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.741888    0.33036917 -0.62490153 ...  7.026625    7.516218\n",
      "   1.366866  ]\n",
      " [ 3.157825    2.3603504  -2.0005322  ...  1.3553047   3.0109286\n",
      "   0.63386786]\n",
      " [ 6.173173    0.5038791  -0.5147208  ...  6.599568    6.9784756\n",
      "   1.2223872 ]\n",
      " ...\n",
      " [ 6.0313377   0.7828322  -0.10996833 ...  6.095717    6.339422\n",
      "   0.9927974 ]\n",
      " [ 2.8011541   2.849734   -0.74870753 ...  1.5070181   1.6759939\n",
      "   0.12455711]\n",
      " [ 6.9192066   0.5435928  -0.5524645  ...  7.3711853   7.750296\n",
      "   1.3544575 ]]\n"
     ]
    }
   ],
   "source": [
    "y_1500rating = model.predict(x_1500history_norm)\n",
    "print(y_1500rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.741888  , 0.33036917, 0.        , ..., 7.026625  , 7.516218  ,\n",
       "        1.366866  ],\n",
       "       [3.157825  , 2.3603504 , 0.        , ..., 1.3553047 , 3.0109286 ,\n",
       "        0.63386786],\n",
       "       [6.173173  , 0.5038791 , 0.        , ..., 6.599568  , 6.9784756 ,\n",
       "        1.2223872 ],\n",
       "       ...,\n",
       "       [6.0313377 , 0.7828322 , 0.        , ..., 6.095717  , 6.339422  ,\n",
       "        0.9927974 ],\n",
       "       [2.8011541 , 2.849734  , 0.        , ..., 1.5070181 , 1.6759939 ,\n",
       "        0.12455711],\n",
       "       [6.9192066 , 0.5435928 , 0.        , ..., 7.3711853 , 7.750296  ,\n",
       "        1.3544575 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range (1500):\n",
    "    for j in range(100):\n",
    "        if y_1500rating[i,j]>10:\n",
    "            y_1500rating[i,j]=10\n",
    "        elif y_1500rating[i,j]<0:\n",
    "            y_1500rating[i,j]=0\n",
    "y_1500rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER ID</th>\n",
       "      <th>alaska basil</th>\n",
       "      <th>alcohol future</th>\n",
       "      <th>alice ticket</th>\n",
       "      <th>alien potato</th>\n",
       "      <th>asia jacket</th>\n",
       "      <th>aztec iris</th>\n",
       "      <th>balance hostel</th>\n",
       "      <th>betty today</th>\n",
       "      <th>boston house</th>\n",
       "      <th>...</th>\n",
       "      <th>trivial neon</th>\n",
       "      <th>tuna relax</th>\n",
       "      <th>tunnel nerve</th>\n",
       "      <th>turtle pierre</th>\n",
       "      <th>update vibrate</th>\n",
       "      <th>vampire teacher</th>\n",
       "      <th>ventura next</th>\n",
       "      <th>vodka bahama</th>\n",
       "      <th>volume pasta</th>\n",
       "      <th>zero nikita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>117520</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3001</td>\n",
       "      <td>117524</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3002</td>\n",
       "      <td>117528</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3003</td>\n",
       "      <td>117534</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3004</td>\n",
       "      <td>117541</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4495</td>\n",
       "      <td>125956</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4496</td>\n",
       "      <td>125959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4497</td>\n",
       "      <td>125960</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4498</td>\n",
       "      <td>125969</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4499</td>\n",
       "      <td>125976</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      USER ID  alaska basil  alcohol future  alice ticket  alien potato  \\\n",
       "3000   117520           7.0             0.0           0.0           2.0   \n",
       "3001   117524           3.0             2.0           0.0           3.0   \n",
       "3002   117528           6.0             1.0           0.0           2.0   \n",
       "3003   117534           8.0             0.0           2.0           2.0   \n",
       "3004   117541           6.0             1.0           0.0           2.0   \n",
       "...       ...           ...             ...           ...           ...   \n",
       "4495   125956           3.0             3.0           0.0           3.0   \n",
       "4496   125959           1.0             6.0           0.0           5.0   \n",
       "4497   125960           6.0             1.0           0.0           2.0   \n",
       "4498   125969           3.0             3.0           0.0           3.0   \n",
       "4499   125976           7.0             1.0           0.0           2.0   \n",
       "\n",
       "      asia jacket  aztec iris  balance hostel  betty today  boston house  ...  \\\n",
       "3000          2.0         2.0             4.0          4.0           3.0  ...   \n",
       "3001          2.0         1.0             3.0          2.0           5.0  ...   \n",
       "3002          2.0         2.0             4.0          4.0           3.0  ...   \n",
       "3003          0.0         1.0             5.0          2.0           2.0  ...   \n",
       "3004          1.0         2.0             4.0          4.0           3.0  ...   \n",
       "...           ...         ...             ...          ...           ...  ...   \n",
       "4495          1.0         1.0             3.0          1.0           4.0  ...   \n",
       "4496          2.0         2.0             6.0          2.0           7.0  ...   \n",
       "4497          1.0         2.0             4.0          4.0           3.0  ...   \n",
       "4498          1.0         1.0             4.0          1.0           4.0  ...   \n",
       "4499          2.0         2.0             4.0          5.0           4.0  ...   \n",
       "\n",
       "      trivial neon  tuna relax  tunnel nerve  turtle pierre  update vibrate  \\\n",
       "3000           7.0         5.0           5.0            0.0             4.0   \n",
       "3001           3.0         3.0           3.0            1.0             1.0   \n",
       "3002           7.0         5.0           4.0            0.0             4.0   \n",
       "3003           5.0         4.0           6.0            3.0             2.0   \n",
       "3004           6.0         5.0           4.0            1.0             4.0   \n",
       "...            ...         ...           ...            ...             ...   \n",
       "4495           2.0         3.0           2.0            2.0             1.0   \n",
       "4496           1.0         5.0           2.0            4.0             0.0   \n",
       "4497           6.0         5.0           4.0            1.0             3.0   \n",
       "4498           2.0         4.0           2.0            2.0             1.0   \n",
       "4499           7.0         5.0           5.0            0.0             4.0   \n",
       "\n",
       "      vampire teacher  ventura next  vodka bahama  volume pasta  zero nikita  \n",
       "3000              7.0           7.0           7.0           8.0          1.0  \n",
       "3001              1.0           2.0           1.0           3.0          1.0  \n",
       "3002              6.0           6.0           7.0           7.0          1.0  \n",
       "3003              7.0           4.0           5.0           4.0          2.0  \n",
       "3004              6.0           7.0           7.0           7.0          1.0  \n",
       "...               ...           ...           ...           ...          ...  \n",
       "4495              1.0           2.0           1.0           2.0          0.0  \n",
       "4496              0.0           2.0           0.0           2.0          0.0  \n",
       "4497              6.0           6.0           6.0           6.0          1.0  \n",
       "4498              1.0           2.0           2.0           2.0          0.0  \n",
       "4499              7.0           7.0           7.0           8.0          1.0  \n",
       "\n",
       "[1500 rows x 101 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newy_test = pd.DataFrame(y_1500rating,index = history.index[3000:],columns = step2.columns[2:]).round(0)\n",
    "newy_test.insert(0,'USER ID', history.iloc[3000:,:]['USER ID'])\n",
    "newy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "newy_test.to_csv(\"step3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
